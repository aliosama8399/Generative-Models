# Generative Models

This repository focuses on implementing and experimenting with various generative models. Generative models are a class of machine learning models designed to generate new data instances that resemble a given training dataset. The following generative models are explored in this project:

## List of Generative Models

1. **Variational Autoencoder (VAE):**
   - **Description:** VAEs are probabilistic generative models that aim to learn a latent representation of input data, allowing for the generation of new samples.

2. **Deep Convolutional Generative Adversarial Network (DCGAN):**
   - **Description:** DCGANs consist of a generator and a discriminator trained adversarially. The generator creates realistic data, and the discriminator distinguishes between real and generated samples.

3. **Style Generative Adversarial Network (Style GAN):**
   - **Description:** Style GANs, an evolution of GANs, focus on generating high-quality and diverse images. They often allow for control over specific attributes of generated samples.

4. **Neural Style Transfer:**
   - **Description:** Neural style transfer involves applying the artistic style of one image to the content of another, creating visually appealing and unique results.

5. **Diffusion Models:**
   - **Description:** Diffusion models learn to generate samples by iteratively refining a noise process. These models, such as the denoising score matching and Langevin dynamics, have shown effectiveness in generating high-quality samples.
